{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and Restoring TensorFlow Models\n",
    "\n",
    "### Â© Jubeen Shah 2018\n",
    "\n",
    "Hey there! Welcome to `J.S Codes` jupyter notebooks for TensorFlow!\n",
    "<br>\n",
    "In this notebook we'll see `Saving and Restoring TensorFlow Models`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a model can take hours. But once you close your TensorFlow session, you lose all the trained weights and biases. If you were to reuse the model in the future, you would have to train it all over again!\n",
    "\n",
    "Fortunately, TensorFlow gives you the ability to save your progress using a class called `tf.train.Saver`. This class provides the functionality to save any `tf.Variable` to your file system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file = './model.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = tf.Variable(tf.truncated_normal([2,3]))\n",
    "bias = tf.Variable(tf.truncated_normal([3]))\n",
    "\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights :\n",
      "[[-1.5922114  -0.7943796   1.5465875 ]\n",
      " [ 0.67522407  0.5711731  -0.5670706 ]]\n",
      "Bias :\n",
      "[ 0.76440656 -0.9569943   0.3302203 ]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(\"Weights :\" )\n",
    "    print(sess.run(weights))\n",
    "    print(\"Bias :\")\n",
    "    print(sess.run(bias))\n",
    "          \n",
    "    saver.save(sess, save_path=save_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Tensors `weights` and `bias` are set to random values using the `tf.truncated_normal()` function. The values are then saved to the save_file location, `\"model.ckpt\"`, using the `tf.train.Saver.save()` function. (The \".ckpt\" extension stands for \"checkpoint\".)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Variables\n",
    "Let's load the tensor variables back, into a new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = tf.Variable(tf.truncated_normal([2,3]))\n",
    "bias = tf.Variable(tf.truncated_normal([3]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model.ckpt\n",
      "Weights : \n",
      "[[-1.5922114  -0.7943796   1.5465875 ]\n",
      " [ 0.67522407  0.5711731  -0.5670706 ]]\n",
      "Bias : \n",
      "[ 0.76440656 -0.9569943   0.3302203 ]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, save_file)\n",
    "    print(\"Weights : \")\n",
    "    print(sess.run(weights))\n",
    "    print(\"Bias : \")\n",
    "    print(sess.run(bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_datat_data\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "n_input = 784\n",
    "n_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting .\\train-images-idx3-ubyte.gz\n",
      "Extracting .\\train-labels-idx1-ubyte.gz\n",
      "Extracting .\\t10k-images-idx3-ubyte.gz\n",
      "Extracting .\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\".\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = tf.placeholder(tf.float32,shape=[None, n_input])\n",
    "labels = tf.placeholder(tf.float32, shape=[None, n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = tf.Variable(tf.random_normal(shape=[n_input, n_classes]))\n",
    "bias = tf.Variable(tf.random_normal(shape=[n_classes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = tf.add(tf.matmul(features, weights), bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=labels))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train the model, and then save the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file = './train_model_mnist.ckpt'\n",
    "batch_size = 128 #reduce the batch size, if enough memory isn't available\n",
    "n_epochs = 100\n",
    "\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0   - Validation Accuracy : 0.10080000013113022\n",
      "Epoch 10  - Validation Accuracy : 0.25220000743865967\n",
      "Epoch 20  - Validation Accuracy : 0.42800000309944153\n",
      "Epoch 30  - Validation Accuracy : 0.5246000289916992\n",
      "Epoch 40  - Validation Accuracy : 0.5874000191688538\n",
      "Epoch 50  - Validation Accuracy : 0.6313999891281128\n",
      "Epoch 60  - Validation Accuracy : 0.6636000275611877\n",
      "Epoch 70  - Validation Accuracy : 0.6909999847412109\n",
      "Epoch 80  - Validation Accuracy : 0.7056000232696533\n",
      "Epoch 90  - Validation Accuracy : 0.7200000286102295\n",
      "training model is now saved!!\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epochs in range(n_epochs):\n",
    "        total_batch = math.ceil(mnist.train.num_examples / batch_size)\n",
    "        \n",
    "        for i in range(total_batch):\n",
    "            batch_features, batch_labels = mnist.train.next_batch(batch_size=batch_size)\n",
    "            sess.run(optimizer, feed_dict= {features : batch_features, labels : batch_labels})\n",
    "            \n",
    "        if epochs % 10 == 0:\n",
    "            valid_accuracy = sess.run(accuracy, feed_dict= {features : mnist.validation.images, labels : mnist.validation.labels})\n",
    "            print('Epoch {:<3} - Validation Accuracy : {}'.format(epochs, valid_accuracy))\n",
    "    saver.save(sess=sess, save_path=save_file)\n",
    "    print('training model is now saved!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./train_model_mnist.ckpt\n",
      "Test Accuracy = 0.7394000291824341\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, save_file)\n",
    "    \n",
    "    test_accuracy = sess.run(accuracy, feed_dict = {features : mnist.test.images, labels : mnist.test.labels})\n",
    "    \n",
    "print('Test Accuracy = {}'.format(test_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
